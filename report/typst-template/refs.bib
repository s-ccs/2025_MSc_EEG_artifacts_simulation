@article{Schepers2025,
 doi = {10.21105/joss.06641},
 url = {https://doi.org/10.21105/joss.06641},
 year = {2025},
 publisher = {The Open Journal},
 volume = {10},
 number = {107},
 pages = {6641},
 author = {Judith Schepers and Luis Lips and Maanik Marathe and Benedikt V. Ehinger},
 title = {UnfoldSim.jl: Simulating continuous event-based time series data for EEG and beyond},
 journal = {Journal of Open Source Software}
 }
 
@book{hari_meg-eeg_2017,
	address = {Cary},
	title = {{MEG}-{EEG} {Primer}},
	isbn = {978-0-19-049778-1},
	url = {https://ebookcentral.proquest.com/lib/uni-stuttgart/detail.action?docID=5746005},
	language = {eng},
	publisher = {Oxford University Press USA - OSO},
	author = {Hari, Riitta},
	collaborator = {Puce, Aina},
	year = {2017},
}

@inproceedings{jas:hal-01313458,
  TITLE = {{Automated rejection and repair of bad trials in MEG/EEG}},
  AUTHOR = {Jas, Mainak and Engemann, Denis and Raimondo, Federico and Bekhti, Yousra and Gramfort, Alexandre},
  URL = {https://hal.science/hal-01313458},
  BOOKTITLE = {{6th International Workshop on Pattern Recognition in Neuroimaging (PRNI)}},
  ADDRESS = {Trento, Italy},
  YEAR = {2016},
  MONTH = Jun,
  KEYWORDS = {magnetoencephalography ; electroencephalography ; preprocessing ; artifact rejection ; automation ; machine learning},
  PDF = {https://hal.science/hal-01313458v1/file/automated-rejection-repair.pdf},
  HAL_ID = {hal-01313458},
  HAL_VERSION = {v1},
}

@article{delorme_eeglab_2004,
	title = {{EEGLAB}: an open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
	volume = {134},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01650270},
	shorttitle = {{EEGLAB}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027003003479},
	doi = {10.1016/j.jneumeth.2003.10.009},
	language = {en},
	number = {1},
	urldate = {2025-03-08},
	journal = {Journal of Neuroscience Methods},
	author = {Delorme, Arnaud and Makeig, Scott},
	month = mar,
	year = {2004},
	pages = {9--21},
	file = {Submitted Version:/home/mnk/Zotero/storage/V8T374IL/Delorme and Makeig - 2004 - EEGLAB an open source toolbox for analysis of single-trial EEG dynamics including independent compo.pdf:application/pdf},
}

@misc{larson_mne-python_2024,
	title = {{MNE}-{Python}},
	copyright = {BSD 3-Clause "New" or "Revised" License},
	url = {https://zenodo.org/doi/10.5281/zenodo.592483},
	abstract = {Full Changelog: https://github.com/mne-tools/mne-python/compare/v1.8.0...v1.9.0},
	urldate = {2025-03-08},
	publisher = {Zenodo},
	author = {Larson, Eric and Gramfort, Alexandre and Engemann, Denis A and Leppakangas, Jaakko and Brodbeck, Christian and Jas, Mainak and Brooks, Teon L and Sassenhagen, Jona and McCloy, Daniel and Luessi, Martin and King, Jean-Rémi and Höchenberger, Richard and Goj, Roman and Brunner, Clemens and Favelier, Guillaume and van Vliet, Marijn and Wronkiewicz, Mark and Rockhill, Alex and Holdgraf, Chris and Scheltienne, Mathieu and Massich, Joan and Appelhoff, Stefan and Bekhti, Yousra and Leggitt, Alan and Dykstra, Andrew and Trachel, Romain and Luke, Robert and De Santis, Lorenzo and Panda, Asish and Magnuski, Mikołaj and Westner, Britta and Wakeman, Dan G and Strohmeier, Daniel and Bharadwaj, Hari and Linzen, Tal and Barachant, Alexandre and Ruzich, Emily and Bailey, Christopher J and Li, Adam and Moutard, Clément and Bloy, Luke and Raimondo, Fede and Nurminen, Jussi and Billinger, Martin and Montoya, Jair and Woodman, Marmaduke and Huberty, Scott and Lee, Ingoo and Schulz, Martin and Foti, Nick and Nangini, Cathy and García Alanis, José C and Orfanos, Dimitri Papadopoulos and Hauk, Olaf and Maddox, Ross and LaPlante, Roan and Drew, Ashley and Dinh, Christoph and Dumas, Guillaume and Martin and Benerradi, Johann and Hartmann, Thomas and Ort, Eduard and Pasler, Paul and Repplinger, Stefan and Rudiuk, Alexander and Radanovic, Ana and Buran, Brad and Woessner, Jacob and Massias, Mathurin and Hämäläinen, Matti and Sripad, Praveen and Chirkov, Valerii and Mullins, Christopher and Raimundo, Félix and Kaneda, Michiru and Alday, Phillip and Pari, Ram and Kornblith, Simon and Halchenko, Yaroslav and Luo, Yu-Han and Kasper, Johannes and Doelling, Keith and Jensen, Mads and Gahlot, Tanay and Binns, Thomas S and Nunes, Adonay and Gütlin, Dirk and Heinila, Erkka and Armeni, Kristijan and kjs and Weinstein, Alejandro and Lamus, Camilo and Galván, Catalina María and Moënne-Loccoz, Cristóbal and Altukhov, Dmitrii and Peterson, Erica and Hanna, Jevri and Houck, Jon and Klein, Natalie and Roujansky, Paul and Luke, Rob and Ruuskanen, Santeri and Kern, Simon and Rantala, Antti and Maess, Burkhard and Forster, Carina and O'Reilly, Christian and Welke, Dominik and Kolkhorst, Henrich and Banville, Hubert and Zhang, Jack and Maksymenko, Kostiantyn and Clarke, Maggie and Anelli, Matteo and Chapochnikov, Nikolai and Bannier, Pierre-Antoine and Choudhary, Saket and Kim, Cora and Klotzsche, Felix and Wong, Fu-Te and Kojcic, Ivana and Nielsen, Jesper Duemose and Lankinen, Kaisu and Tabavi, Kambiz and Thibault, Louis and Gerster, Moritz and Alibou, Nabil and Gayraud, Nathalie and Ward, Nick and Herbst, Sophie and Férat, Victor and Quinn, Andrew and Gauthier, Antoine and Pinsard, Basile and Stephen, Emily and Hornberger, Erik and Hathaway, Evan and Kalenkovich, Evgenii and Mamashli, Fahimeh and Belonosov, Gennadiy and O'Neill, George and Marinato, Giorgio and Anevar, Hafeza and Abdelhedi, Hamza and Sosulski, Jan and Stout, Jeff and Calder-Travis, Joshua and Zhu, Judy D and Eisenman, Larry and Esch, Lorenz and Dovgialo, Marian and Barascud, Nicolas and Legrand, Nicolas and Kapralov, Nikolai and Chu, Qian and Falach, Rotem and Deslauriers-Gauthier, Samuel and Cotroneo, Silvia and Matindi, Steve and Bierer, Steven and Binns, Thomas Samuel and Stenner, Tristan and Peterson, Victoria and Baratz, Zvi and Tonin, Alessandro and Kovrig, Alexander and Pascarella, Annalisa and Karekal, Apoorva and de la Torre, Carlos and Gohil, Chetan and Zhao, Christina and Krzemiński, Dominik and Makowski, Dominique and Mikulan, Ezequiel and Hofer, Florian and Schiratti, Jean-Baptiste and Evans, Jen and Veillette, John and Drew, Jordan and Teves, Joshua and Mathewson, Kyle and Gwilliams, Laura and Varghese, Lenny and Hamilton, Liberty and Gemein, Lukas and Hecker, Lukas and Lx37 and van Es, Mats and Boggess, Matt and Eberlein, Matthias and Žák, Michal and Sherif, Mohamed and Kozhemiako, Nataliia and Srinivasan, Naveen and Wilming, Niklas and Kozynets, Oleh and Molfese, Peter J and Ablin, Pierre and Das, Proloy and Bertrand, Quentin and Shoorangiz, Reza and Scholz, Richard and Hübner, Rodrigo and Sommariva, Sara and Er, Sena and Khan, Sheraz and Datta, Sumalyo and Papadopoulo, Theodore and Donoghue, Thomas and Jochmann, Thomas and Merk, Timon and Flak, Tod and Dupré la Tour, Tom and NessAiver, Tziona and akshay0724 and sviter and Earle-Richardson, Aaron and Hindle, Abram and Koutsou, Achilleas and Fecker, Adeline and Wagner, Adina and Ciok, Alex and Lepauvre, Alex and Kiefer, Alexander and Gilbert, Andy and Pradhan, Aniket and Padee, Anna and Dubarry, Anne-Sophie and Waniek, Anton Nikolas and Singhal, Archit and Rokem, Ariel and Pelzer, Arne and Hurst, Austin and Beasley, Ben and Nicenboim, Bruno and Clauss, Christian and Mista, Christian and Li, Chun-Hui and Braboszcz, Claire and Schad, Daniel C and Hasegan, Daniel and Tse, Daniel and Sleiter, Darin Erat and Haslacher, David and Sabbagh, David and Kostas, Demetres and Petkova, Desislava and Issagaliyeva, Dinara and Das, Diptyajit and Wetzel, Dominik and Eich, Eberhard and DuPre, Elizabeth and Lau, Ellen and Olivetti, Emanuele and Varano, Enrico and Altamiranda, Enzo and Brayet, Eric and de Montalivet, Etienne and Goldstein, Evgeny and Negahbani, Farzin and Zamberlan, Federico and Pop, Florin and Weber, Frederik D and Tan, Gansheng and Brookshire, Geoff and Giulio and Reina, Gonzalo and Maymandi, Hamid and Arzoo, Hasrat Ali and Sonntag, Hermann and Ye, Hongjiang and Shin, Hyonyoung and Elmas, Hüseyin Orkun and AZZ, Ilian and Machairas, Ilias and Zubarev, Ivan and de Jong, Ivo and Phelan, Jacob and Kaczmarzyk, Jakub and Zerfowski, Jan and van den Bosch, Jasper J F and Van Der Donckt, Jeroen and van der Meer, Johan and Niediek, Johannes and Koen, Josh and Bear, Joshua J and Dammers, Juergen and Galán, Julia Guiomar Niso and Welzel, Julius and Slama, Katarina and Leinweber, Katrin and Grabot, Laetitia and Andersen, Lau Møller and Almeida, Leonardo Rochael and Barbosa, Leonardo S and Alfine, Lorenzo and Hejtmánek, Lukáš and Balatsko, Maksym and Kitzbichler, Manfred and Kumar, Manoj and Kadwani, Manorama and Sutela, Manu and Koculak, Marcin and Henney, Mark and BaBer, Martin and Oberg, Martin and van Harmelen, Martin and Courtemanche, Matt and Tucker, Matt and Visconti di Oleggio Castello, Matteo and Dold, Matthias and Toivonen, Matti and Shader, Maureen and Cespedes, Mauricio and Krause, Michael and Rybář, Milan and He, Mingjian and Daneshzand, Mohammad and Fourcaud-Trocmé, Nicolas and Gensollen, Nicolas and Proulx, Nicole and Focke, Niels and Chalas, Nikolas and Markowitz, Noah and Shubi, Omer and Mainar, Pablo and Sundaram, Padma and Silva, Pedro and Li, Quanliang and Barthélemy, Quentin and Nadkarni, Rahul and Gatti, Ramiro and Apariciogarcia, Ramonapariciog and Aagaard, Rasmus and Nasri, Reza and Koehler, Richard and Stargardsky, Riessarius and Oostenveld, Robert and Seymour, Robert and Schirrmeister, Robin Tibor and Law, Ryan and Pai, Sagun and Perry, Sam and Louviot, Samuel and Saha, Sawradip and Mathot, Sebastiaan and Major, Sebastian and Treguer, Sebastien and Castaño, Sebastián and Deng, Senwen and Antopolskiy, Sergey and Shirazi, Seyed (Yahya) and Wong, Simeon and Hofmann, Simon M and Poil, Simon-Shlomo and Foslien, Sondre and Singh, Sourav and Chambon, Stanislas and Bethard, Steven and Gutstein, Steven M and Meyer, Svea Marie and Wang, T and Moreau, Thomas and Radman, Thomas and Gates, Timothy and Ma, Tom and Stone, Tom and Clausner, Tommy and Anijärv, Toomas Erik and Kumaravel, Velu Prabhakar and Turner, Will and Zuazo, Xabier de and Xia, Xiaokai and Zuo, Yiping and Zhang, Zhi and ZENG, Ziyi and btkcodedev and buildqa and luzpaz},
	month = dec,
	year = {2024},
	doi = {10.5281/ZENODO.592483},
	keywords = {DBS, deep brain stimulation, eCoG, EEG, electrocorticography, electroencephalography, fNIRS, functional near-infrared spectroscopy, iEEG, intracranial EEG, magnetoencephalography, MEG},
}


@misc{ehinger_unfoldjl_2025,
	title = {Unfold.jl: event-related regression toolbox},
	copyright = {MIT License},
	shorttitle = {Unfold.jl},
	url = {https://zenodo.org/doi/10.5281/zenodo.14652576},
	abstract = {Unfold v0.8.1

Diff since v0.8.0

Bugfix: residuals were incorrectly calculated in the case the data is longer than the model

Merged pull requests:



Update predict.jl (\#244) (@behinger)},
	urldate = {2025-03-08},
	publisher = {Zenodo},
	author = {Ehinger, Benedikt and Alday, Phillip},
	month = jan,
	year = {2025},
	doi = {10.5281/ZENODO.14652576},
	keywords = {circular, EEG, ERP, event-related potentials, fMRI, GLM, MixedModels, non-linear, non-linear ERP, regression ERP, rERP, statistics},
}

@article{krol_sereega_2018,
	title = {{SEREEGA}: {Simulating} event-related {EEG} activity},
	volume = {309},
	issn = {01650270},
	shorttitle = {{SEREEGA}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027018302395},
	doi = {10.1016/j.jneumeth.2018.08.001},
	language = {en},
	urldate = {2025-03-08},
	journal = {Journal of Neuroscience Methods},
	author = {Krol, Laurens R. and Pawlitzki, Juliane and Lotte, Fabien and Gramann, Klaus and Zander, Thorsten O.},
	month = nov,
	year = {2018},
	pages = {13--24},
}

@article{barbara_monopolar_2023,
	title = {Monopolar and bipolar electrooculography signal characteristics due to target displacements—have we seen the whole picture?},
	volume = {44},
	issn = {0967-3334, 1361-6579},
	url = {https://iopscience.iop.org/article/10.1088/1361-6579/acb03d},
	doi = {10.1088/1361-6579/acb03d},
	abstract = {The development of electrooculography (EOG)-based human-computer interface systems is generally based on the processing of the commonly referred to horizontal and vertical bipolar EOG channels, which are computed from a horizontally-aligned and another vertically-aligned pair of electrodes, respectively. Horizontal (vertical) target displacements are assumed to result in changes in the horizontal (vertical) EOG channel only, and any cross-talk between the bipolar channels is often neglected or incorrectly attributed solely to electrode misalignment with respect to the ocular rotation axes. Objective. The aim of this work is to demonstrate that such cross-talk is intrinsic to the geometric relationship between the orientation of the verging ocular globes and the planar displacement of the gaze target with respect to the primary gaze position. Approach. Since it is difﬁcult to record actual EOG data with electrodes which are perfectly-aligned with the ocular rotation axes, this is studied by simulating the EOG potential values for various horizontally- and vertically-displacing targets using a dipole model of the eye. Main results. We show that cross-talk between the horizontal and vertical bipolar EOG channels is manifested even if the electrodes are aligned with the ocular rotation axes. Speciﬁcally, for a horizontally- (vertically-)displaced target, while the monopolar EOG signals obtained from the horizontally- (vertically-)aligned electrodes exhibit an expected predominant potential displacement, a smaller displacement is also exhibited in the monopolar EOG signals obtained from the vertically- (horizontally-)aligned electrodes. These unexpected displacements in the vertically- (horizontally-)aligned monopolar channels may have different magnitudes, resulting in an effective potential displacement in the vertical (horizontal) bipolar EOG channel. Signiﬁcance. This is signiﬁcant as it shows that, unlike in many works published so far for EOG-based ocular pose estimation, it is not sufﬁcient to only use the horizontal (vertical) bipolar EOG channel to estimate the horizontal (vertical) displacement of the ocular pose.},
	language = {en},
	number = {3},
	urldate = {2024-09-23},
	journal = {Physiological Measurement},
	author = {Barbara, Nathaniel and Camilleri, Tracey A and Camilleri, Kenneth P},
	month = mar,
	year = {2023},
	pages = {035011},
	file = {PDF:/home/mnk/Zotero/storage/22997IKU/Barbara et al. - 2023 - Monopolar and bipolar electrooculography signal characteristics due to target displacements—have we.pdf:application/pdf},
}


@article{BARZEGARAN2019108377,
title = {EEGSourceSim: A framework for realistic simulation of EEG scalp data using MRI-based forward models and biologically plausible signals and noise},
journal = {Journal of Neuroscience Methods},
volume = {328},
pages = {108377},
year = {2019},
issn = {0165-0270},
doi = {https://doi.org/10.1016/j.jneumeth.2019.108377},
url = {https://www.sciencedirect.com/science/article/pii/S0165027019302341},
author = {Elham Barzegaran and Sebastian Bosse and Peter J. Kohler and Anthony M. Norcia},
keywords = {EEG simulation, Forward model, Inverse model, Functional connectivity, Spatial filtering, Regions of interest},
abstract = {Background
Electroencephalography (EEG) is widely used to investigate human brain function. Simulation studies are essential for assessing the validity of EEG analysis methods and the interpretability of results.
New method
Here we present a simulation environment for generating EEG data by embedding biologically plausible signal and noise into MRI-based forward models that incorporate individual-subject variability in structure and function.
Results
The package includes pipelines for the evaluation and validation of EEG analysis tools for source estimation, functional connectivity, and spatial filtering. EEG dynamics can be simulated using realistic noise and signal models with user specifiable signal-to-noise ratio (SNR). We also provide a set of quantitative metrics tailored to source estimation, connectivity and spatial filtering applications.
Comparison with existing method(s)
We provide a larger set of forward solutions for individual MRI-based head models than has been available previously. These head models are surface-based and include two sets of regions-of-interest (ROIs) that have been brought into registration with the brain of each individual using surface-based alignment – one from a whole brain and the other from a visual cortex atlas. We derive a realistic model of noise by fitting different model components to measured resting state EEG. We also provide a set of quantitative metrics for evaluating source-localization, functional connectivity and spatial filtering methods.
Conclusions
The inclusion of a larger number of individual head-models, combined with surface-atlas based labeling of ROIs and plausible models of signal and noise, allows for simulation of EEG data with greater realism than previous packages.}
}

@misc{couchman2024simulatedeyeblinkartifactremoval,
      title={Simulated Eyeblink Artifact Removal with ICA: Effect of Measurement Uncertainty}, 
      author={Jennie Couchman and Orestis Kaparounakis and Chatura Samarakoon and Phillip Stanley-Marbell},
      year={2024},
      eprint={2410.03261},
      archivePrefix={arXiv},
      primaryClass={eess.SY},
      url={https://arxiv.org/abs/2410.03261}, 
}

@article{anzolinArticle,
author = {Anzolin, Alessandra and Toppi, Jlenia and Petti, Manuela and Cincotti, Febo and Astolfi, Laura},
year = {2021},
month = {05},
pages = {3632},
title = {SEED-G: Simulated EEG Data Generator for Testing Connectivity Algorithms},
volume = {21},
journal = {Sensors},
doi = {10.3390/s21113632}
}

@article{KLADOS20161004,
title = {A semi-simulated EEG/EOG dataset for the comparison of EOG artifact rejection techniques},
journal = {Data in Brief},
volume = {8},
pages = {1004-1006},
year = {2016},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2016.06.032},
url = {https://www.sciencedirect.com/science/article/pii/S2352340916304000},
author = {Manousos A. Klados and Panagiotis D. Bamidis},
keywords = {EEG, EOG, Artifact Rejection},
abstract = {Artifact rejection techniques are used to recover the brain signals underlying artifactual electroencephalographic (EEG) segments. Although over the last few years many different artifact rejection techniques have been proposed (http://dx.doi.org/10.1109/JSEN.2011.2115236 [1], http://dx.doi.org/10.1016/j.clinph.2006.09.003 [2], http://dx.doi.org/10.3390/e16126553 [3]), none has been established as a gold standard so far, because assessing their performance is difficult and subjective (http://dx.doi.org/10.1109/ITAB.2009.5394295 [4], http://dx.doi.org/10.1016/j.bspc.2011.02.001 [5], http://dx.doi.org/10.1007/978-3-540-89208-3_300. [6]). This limitation is mainly based on the fact that the underlying artifact-free brain signal is unknown, so there is no objective way to measure how close the retrieved signal is to the real one. This article solves the aforementioned problem by presenting a semi-simulated EEG dataset, where artifact-free EEG signals are manually contaminated with ocular artifacts, using a realistic head model. The significant part of this dataset is that it contains the pre-contamination EEG signals, so the brain signals underlying the EOG artifacts are known and thus the performance of every artifact rejection technique can be objectively assessed.}
}

@article{duToit_Venter_van_den_Heever_2021, title={Semi-Synthetic EEG Data for the Evaluation of EEG Cleaning Methods}, url={http://dx.doi.org/10.2139/ssrn.3995406}, DOI={10.2139/ssrn.3995406}, journal={SSRN Electronic Journal}, publisher={Elsevier BV}, author={du Toit, Wadda Benjamin and Venter, Martin and van den Heever, David}, year={2021}, language={en} } 

@ARTICLE{Mutanen,
  
AUTHOR={Mutanen, Tuomas Petteri  and Ilmoniemi, Ida  and Atti, Iiris  and Metsomaa, Johanna  and Ilmoniemi, Risto Juhani },
         
TITLE={A simulation study: comparing independent component analysis and signal-space projection – source-informed reconstruction for rejecting muscle artifacts evoked by transcranial magnetic stimulation},
        
JOURNAL={Frontiers in Human Neuroscience},
        
VOLUME={Volume 18 - 2024},

YEAR={2024},

URL={https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2024.1324958},

DOI={10.3389/fnhum.2024.1324958},

ISSN={1662-5161},

ABSTRACT={<sec id="sec1"><title>Introduction</title><p>The combination of transcranial magnetic stimulation (TMS) and electroencephalography (EEG) allows researchers to explore cortico-cortical connections. To study effective connections, the first few tens of milliseconds of the TMS-evoked potentials are the most critical. Yet, TMS-evoked artifacts complicate the interpretation of early-latency data. Data-processing strategies like independent component analysis (ICA) and the combined signal-space projection–source-informed reconstruction approach (SSP–SIR) are designed to mitigate artifacts, but their objective assessment is challenging because the true neuronal EEG responses under large-amplitude artifacts are generally unknown. Through simulations, we quantified how the spatiotemporal properties of the artifacts affect the cleaning performances of ICA and SSP–SIR.</p></sec><sec id="sec2"><title>Methods</title><p>We simulated TMS-induced muscle artifacts and superposed them on pre-processed TMS–EEG data, serving as the ground truth. The simulated muscle artifacts were varied both in terms of their topography and temporal profiles. The signals were then cleaned using ICA and SSP–SIR, and subsequent comparisons were made with the ground truth data.</p></sec><sec id="sec3"><title>Results</title><p>ICA performed better when the artifact time courses were highly variable across the trials, whereas the effectiveness of SSP–SIR depended on the congruence between the artifact and neuronal topographies, with the performance of SSP–SIR being better when difference between topographies was larger. Overall, SSP–SIR performed better than ICA across the tested conditions. Based on these simulations, SSP–SIR appears to be more effective in suppressing TMS-evoked muscle artifacts. These artifacts are shown to be highly time-locked to the TMS pulse and manifest in topographies that differ substantially from the patterns of neuronal potentials.</p></sec><sec id="sec4"><title>Discussion</title><p>Selecting between ICA and SSP–SIR should be guided by the characteristics of the artifacts. SSP–SIR might be better equipped for suppressing time-locked artifacts, provided that their topographies are sufficiently different from the neuronal potential patterns of interest, and that the SSP–SIR algorithm can successfully find those artifact topographies from the high-pass-filtered data. ICA remains a powerful tool for rejecting artifacts that are not strongly time locked to the TMS pulse.</p></sec>}}

@article{harmening_hartmutmodeling_2022,
	title = {{HArtMuT}—modeling eye and muscle contributors in neuroelectric imaging},
	volume = {19},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/aca8ce},
	doi = {10.1088/1741-2552/aca8ce},
	abstract = {Objective. Magneto- and electroencephalography (M/EEG) measurements record a mix of signals from the brain, eyes, and muscles. These signals can be disentangled for artifact cleaning e.g. using spatial filtering techniques. However, correctly localizing and identifying these components relies on head models that so far only take brain sources into account. Approach. We thus developed the Head Artifact Model using Tripoles (HArtMuT). This volume conduction head model extends to the neck and includes brain sources as well as sources representing eyes and muscles that can be modeled as single dipoles, symmetrical dipoles, and tripoles. We compared a HArtMuT four-layer boundary element model (BEM) with the EEGLAB standard head model on their localization accuracy and residual variance (RV) using a HArtMuT finite element model (FEM) as ground truth. We also evaluated the RV on real-world data of mobile participants, comparing different HArtMuT BEM types with the EEGLAB standard head model. Main results. We found that HArtMuT improves localization for all sources, especially non-brain, and localization error and RV of non-brain sources were in the same range as those of brain sources. The best results were achieved by using cortical dipoles, muscular tripoles, and ocular symmetric dipoles, but dipolar sources alone can already lead to convincing results. Significance. We conclude that HArtMuT is well suited for modeling eye and muscle contributions to the M/EEG signal. It can be used to localize sources and to identify brain, eye, and muscle components. HArtMuT is freely available and can be integrated into standard software.},
	language = {en},
	number = {6},
	urldate = {2024-09-04},
	journal = {Journal of Neural Engineering},
	author = {Harmening, Nils and Klug, Marius and Gramann, Klaus and Miklody, Daniel},
	month = dec,
	year = {2022},
	pages = {066041},
	file = {PDF:/home/mnk/Zotero/storage/XH5LU5RJ/Harmening et al. - 2022 - HArtMuT—modeling eye and muscle contributors in neuroelectric imaging.pdf:application/pdf},
}

@misc{Yu_Hairston_2021,
  title={Open EEG Phantom},
  url={osf.io/qrka2},
  DOI={10.17605/OSF.IO/QRKA2},
  publisher={OSF},
  author={Yu, Alfred B and Hairston, W. D},
  year={2021},
  month={Jan}
}

@Article{s23198214,
AUTHOR = {Downey, Ryan J. and Ferris, Daniel P.},
TITLE = {iCanClean Removes Motion, Muscle, Eye, and Line-Noise Artifacts from Phantom EEG},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {19},
ARTICLE-NUMBER = {8214},
URL = {https://www.mdpi.com/1424-8220/23/19/8214},
PubMedID = {37837044},
ISSN = {1424-8220},
ABSTRACT = {The goal of this study was to test a novel approach (iCanClean) to remove non-brain sources from scalp EEG data recorded in mobile conditions. We created an electrically conductive phantom head with 10 brain sources, 10 contaminating sources, scalp, and hair. We tested the ability of iCanClean to remove artifacts while preserving brain activity under six conditions: Brain, Brain + Eyes, Brain + Neck Muscles, Brain + Facial Muscles, Brain + Walking Motion, and Brain + All Artifacts. We compared iCanClean to three other methods: Artifact Subspace Reconstruction (ASR), Auto-CCA, and Adaptive Filtering. Before and after cleaning, we calculated a Data Quality Score (0–100%), based on the average correlation between brain sources and EEG channels. iCanClean consistently outperformed the other three methods, regardless of the type or number of artifacts present. The most striking result was for the condition with all artifacts simultaneously present. Starting from a Data Quality Score of 15.7% (before cleaning), the Brain + All Artifacts condition improved to 55.9% after iCanClean. Meanwhile, it only improved to 27.6%, 27.2%, and 32.9% after ASR, Auto-CCA, and Adaptive Filtering. For context, the Brain condition scored 57.2% without cleaning (reasonable target). We conclude that iCanClean offers the ability to clear multiple artifact sources in real time and could facilitate human mobile brain-imaging studies with EEG.},
DOI = {10.3390/s23198214}
}

@article{mowrer_corneo-retinal_1935,
	title = {{THE} {CORNEO}-{RETINAL} {POTENTIAL} {DIFFERENCE} {AS} {THE} {BASIS} {OF} {THE} {GALVANOMETRIC} {METHOD} {OF} {RECORDING} {EYE} {MOVEMENTS}},
	volume = {114},
	issn = {0002-9513},
	url = {https://www.physiology.org/doi/10.1152/ajplegacy.1935.114.2.423},
	doi = {10.1152/ajplegacy.1935.114.2.423},
	language = {en},
	number = {2},
	urldate = {2024-09-23},
	journal = {American Journal of Physiology-Legacy Content},
	author = {Mowrer, O. H. and Ruch, T. C. and Miller, N. E.},
	month = dec,
	year = {1935},
	pages = {423--428},
	file = {PDF:/home/mnk/Zotero/storage/S5VFJRU8/Mowrer et al. - 1935 - THE CORNEO-RETINAL POTENTIAL DIFFERENCE AS THE BASIS OF THE GALVANOMETRIC METHOD OF RECORDING EYE MO.pdf:application/pdf},
}


@article{de_cheveigne_zapline_2020,
	title = {{ZapLine}: {A} simple and effective method to remove power line artifacts},
	volume = {207},
	issn = {10538119},
	shorttitle = {{ZapLine}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811919309474},
	doi = {10.1016/j.neuroimage.2019.116356},
	language = {en},
	urldate = {2025-05-30},
	journal = {NeuroImage},
	author = {De Cheveigné, Alain},
	month = feb,
	year = {2020},
	pages = {116356},
	file = {Full Text:/home/mnk/Zotero/storage/ADBYPE6S/De Cheveigné - 2020 - ZapLine A simple and effective method to remove power line artifacts.pdf:application/pdf},
}


@article{uriguen_eeg_2015,
	title = {{EEG} artifact removal—state-of-the-art and guidelines},
	volume = {12},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2560/12/3/031001},
	doi = {10.1088/1741-2560/12/3/031001},
	abstract = {This paper presents an extensive review on the artifact removal algorithms used to remove the main sources of interference encountered in the electroencephalogram (EEG), speciﬁcally ocular, muscular and cardiac artifacts. We ﬁrst introduce background knowledge on the characteristics of EEG activity, of the artifacts and of the EEG measurement model. Then, we present algorithms commonly employed in the literature and describe their key features. Lastly, principally on the basis of the results provided by various researchers, but also supported by our own experience, we compare the state-of-the-art methods in terms of reported performance, and provide guidelines on how to choose a suitable artifact removal algorithm for a given scenario. With this review we have concluded that, without prior knowledge of the recorded EEG signal or the contaminants, the safest approach is to correct the measured EEG using independent component analysis—to be precise, an algorithm based on second-order statistics such as second-order blind identiﬁcation (SOBI). Other effective alternatives include extended information maximization (InfoMax) and an adaptive mixture of independent component analyzers (AMICA), based on higher order statistics. All of these algorithms have proved particularly effective with simulations and, more importantly, with data collected in controlled recording conditions. Moreover, whenever prior knowledge is available, then a constrained form of the chosen method should be used in order to incorporate such additional information. Finally, since which algorithm is the best performing is highly dependent on the type of the EEG signal, the artifacts and the signal to contaminant ratio, we believe that the optimal method for removing artifacts from the EEG consists in combining more than one algorithm to correct the signal using multiple processing stages, even though this is an option largely unexplored by researchers in the area.},
	language = {en},
	number = {3},
	urldate = {2025-05-29},
	journal = {Journal of Neural Engineering},
	author = {Urigüen, Jose Antonio and Garcia-Zapirain, Begoña},
	month = jun,
	year = {2015},
	pages = {031001},
	file = {PDF:/home/mnk/Zotero/storage/NKXPY296/Urigüen and Garcia-Zapirain - 2015 - EEG artifact removal—state-of-the-art and guidelines.pdf:application/pdf},
}

@article{romero_comparative_2008,
	title = {A comparative study of automatic techniques for ocular artifact reduction in spontaneous {EEG} signals based on clinical target variables: {A} simulation case},
	volume = {38},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00104825},
	shorttitle = {A comparative study of automatic techniques for ocular artifact reduction in spontaneous {EEG} signals based on clinical target variables},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482507001850},
	doi = {10.1016/j.compbiomed.2007.12.001},
	language = {en},
	number = {3},
	urldate = {2025-06-02},
	journal = {Computers in Biology and Medicine},
	author = {Romero, Sergio and Mañanas, Miguel A. and Barbanoj, Manel J.},
	month = mar,
	year = {2008},
	pages = {348--360},
	file = {Full Text:/home/mnk/Zotero/storage/T7NYATG9/Romero et al. - 2008 - A comparative study of automatic techniques for ocular artifact reduction in spontaneous EEG signals.pdf:application/pdf},
}

@article{leske_reducing_2019,
	title = {Reducing power line noise in {EEG} and {MEG} data via spectrum interpolation},
	volume = {189},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811919300266},
	doi = {10.1016/j.neuroimage.2019.01.026},
	language = {en},
	urldate = {2025-05-30},
	journal = {NeuroImage},
	author = {Leske, Sabine and Dalal, Sarang S.},
	month = apr,
	year = {2019},
	pages = {763--776},
	file = {Accepted Version:/home/mnk/Zotero/storage/CD99UBEJ/Leske and Dalal - 2019 - Reducing power line noise in EEG and MEG data via spectrum interpolation.pdf:application/pdf},
}

@article{KIM2025110465,
title = {Juggler’s ASR: Unpacking the principles of artifact subspace reconstruction for revision toward extreme MoBI},
journal = {Journal of Neuroscience Methods},
volume = {420},
pages = {110465},
year = {2025},
issn = {0165-0270},
doi = {https://doi.org/10.1016/j.jneumeth.2025.110465},
url = {https://www.sciencedirect.com/science/article/pii/S0165027025001062},
author = {Hyeonseok Kim and Chi-Yuan Chang and Christian Kothe and John Rehner Iversen and Makoto Miyakoshi},
keywords = {EEG, Artifact rejection, Data cleaning, Artifact subspace reconstruction (ASR), Mobile brain-body imaging (MoBI), Non-stationarity},
abstract = {Background
To improve the Artifact Subspace Reconstruction (ASR) algorithm's performance for real-world EEG data by addressing the problem of low-quality or no calibration data identification in the original ASR (ASRoriginal) algorithm.
New method
We proposed a new method for defining high-quality calibration data using point-by-point amplitude evaluation to eliminate collateral rejection of clean data, which is identified as the major cause of the problem with ASRoriginal. We compared non-parametric and parametric approaches, namely Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and the Generalized Extreme Value (GEV) distribution (ASRDBSCAN and ASRGEV, respectively).
Results (Comparison with existing methods)
We demonstrated the effectiveness of these approaches on simulated and real EEG data. Simulation results showed that ASRDBSCAN and ASRGEV removed simulated artifacts completely where ASRoriginal failed, both in time- and frequency-domain evaluations. In empirical data from 205-channel EEG recordings during a three-ball juggling task (n = 13), ASRDBSCAN found 42 % and ASRGEV found 24 % of data usable for calibration on average, compared to only 9 % by ASRoriginal. Subsequent Independent Component Analysis (ICA) showed that data preprocessed with ASRDBSCAN and ASRGEV produced brain ICs that accounted for more variance of the original data (30 % and 29 %) compared to ASRoriginal (26 %).
Conclusions
The proposed ASRDBSCAN and ASRGEV methods handle motion-related artifacts better than the original ASR algorithm, enabling researchers to better extract brain activity during real-world motor tasks. These methods provide a practical advantage in processing EEG data from experiments involving high-intensity motor activities, advancing biomedical research capabilities.}
}

@unpublished{mmar-researchproject,
  author = "Maanik Marathe",
  title  = "Simulation of Eye Movement Artefacts in EEG: introducing the Ensemble and Corneo-Retinal Dipole methods",
  url = {https://github.com/s-ccs/2024-ocular-artifacts-simulation/blob/d6d6294222603304a7b52a7c1b21b149dcc4fc75/report/thesis/report_2025-03-31.pdf},
  urldate = {2025-03-31},
  year = {2025},
}

@book{malmivuo_bioelectromagnetismprinciples_1995,
	title = {{BioelectromagnetismPrinciples} and {Applications} of {Bioelectric} and {Biomagnetic} {Fields}},
	isbn = {978-0-19-505823-9},
	url = {https://academic.oup.com/book/25966},
	language = {en},
	urldate = {2024-09-12},
	publisher = {Oxford University Press},
	author = {Malmivuo, Jaakko and Plonsey, Robert},
	month = oct,
	year = {1995},
	doi = {10.1093/acprof:oso/9780195058239.001.0001},
	doi = {10.1093/acprof:oso/9780195058239.001.0001},
	file = {PDF:/home/mnk/Zotero/storage/7SMH9EUA/Malmivuo and Plonsey - 1995 - BioelectromagnetismPrinciples and Applications of Bioelectric and Biomagnetic Fields.pdf:application/pdf},
}

@article{iwasaki_effects_2005,
	title = {Effects of eyelid closure, blinks, and eye movements on the electroencephalogram},
	volume = {116},
	issn = {1388-2457},
	url = {https://www.sciencedirect.com/science/article/pii/S138824570400416X},
	doi = {https://doi.org/10.1016/j.clinph.2004.11.001},
	abstract = {Objective To characterize the effects of the eyeball and eyelid positions during eyeblinks on electroencephalographic (EEG) potentials. Methods Movements of the upper eyelids and eyes were measured in two healthy subjects using the magnetic search coil technique during horizontal and vertical eye rotations, eyeblinks, and lid closure. Corresponding signal changes were recorded simultaneously on the electroencephalogram (EEG). Results Spontaneous blinks produced small eye movements directed down and inward, whereas slow or forced blinks were associated with delayed upward eye rotations (i.e. Bell's phenomenon); both types of blinks caused positive EEG potentials with bifrontal distribution maximum at Fp1 and Fp2. Conclusions In prior reports, these positive EEG artifacts have been attributed to upward eyeball rotation during blinks—Bell's phenomenon. By contrast, our findings indicate that movements of the eyelid contribute to a greater extent to these EEG potentials than do upward eyeball rotations. Significance Care is required in attributing EEG artifacts to movements of either eyeball or eyelid, since our findings suggest that they both contribute to these potentials.},
	number = {4},
	journal = {Clinical Neurophysiology},
	author = {Iwasaki, Masaki and Kellinghaus, Christoph and Alexopoulos, Andreas V. and Burgess, Richard C. and Kumar, Arun N. and Han, Yanning H. and Lüders, Hans O. and Leigh, R. John},
	year = {2005},
	keywords = {Artifacts, Blinks, Electroencephalogram, Eye movements, Eyelid, Saccades},
	pages = {878--885},
	file = {ScienceDirect Full Text PDF:/home/mnk/Zotero/storage/7NFS3KET/Iwasaki et al. - 2005 - Effects of eyelid closure, blinks, and eye movements on the electroencephalogram.pdf:application/pdf},
}

@article{matsuo_electrical_1975,
	title = {Electrical phenomena associated with movements of the eyelid},
	volume = {38},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00134694},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0013469475901911},
	doi = {10.1016/0013-4694(75)90191-1},
	language = {en},
	number = {5},
	urldate = {2025-02-23},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Matsuo, Fumisuke and Peters, Jon F and Reilly, Edward L},
	month = may,
	year = {1975},
	pages = {507--511},
}

@article{plochl_combining_2012,
	title = {Combining {EEG} and eye tracking: identification, characterization, and correction of eye movement artifacts in electroencephalographic data},
	volume = {6},
	issn = {1662-5161},
	shorttitle = {Combining {EEG} and eye tracking},
	url = {https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2012.00278/full},
	doi = {10.3389/fnhum.2012.00278},
	abstract = {{\textless}p{\textgreater}Eye movements introduce large artifacts to electroencephalographic recordings (EEG) and thus render data analysis difficult or even impossible. Trials contaminated by eye movement and blink artifacts have to be discarded, hence in standard EEG-paradigms subjects are required to fixate on the screen. To overcome this restriction, several correction methods including regression and blind source separation have been proposed. Yet, there is no automated standard procedure established. By simultaneously recording eye movements and 64-channel-EEG during a guided eye movement paradigm, we investigate and review the properties of eye movement artifacts, including corneo-retinal dipole changes, saccadic spike potentials and eyelid artifacts, and study their interrelations during different types of eye- and eyelid movements. In concordance with earlier studies our results confirm that these artifacts arise from different independent sources and that depending on electrode site, gaze direction, and choice of reference these sources contribute differently to the measured signal. We assess the respective implications for artifact correction methods and therefore compare the performance of two prominent approaches, namely linear regression and independent component analysis (ICA). We show and discuss that due to the independence of eye artifact sources, regression-based correction methods inevitably over- or under-correct individual artifact components, while ICA is in principle suited to address such mixtures of different types of artifacts. Finally, we propose an algorithm, which uses eye tracker information to objectively identify eye-artifact related ICA-components (ICs) in an automated manner. In the data presented here, the algorithm performed very similar to human experts when those were given both, the topographies of the ICs and their respective activations in a large amount of trials. Moreover it performed more reliable and almost twice as effective than human experts when those had to base their decision on IC topographies only. Furthermore, a receiver operating characteristic (ROC) analysis demonstrated an optimal balance of false positive and false negative at an area under curve (AUC) of more than 0.99. Removing the automatically detected ICs from the data resulted in removal or substantial suppression of ocular artifacts including microsaccadic spike potentials, while the relevant neural signal remained unaffected. In conclusion the present work aims at a better understanding of individual eye movement artifacts, their interrelations and the respective implications for eye artifact correction. Additionally, the proposed ICA-procedure provides a tool for optimized detection and correction of eye movement-related artifact components.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-12-20},
	journal = {Frontiers in Human Neuroscience},
	author = {Plöchl, Michael and Ossandón, José Pablo and König, Peter},
	month = oct,
	year = {2012},
	note = {Publisher: Frontiers},
	keywords = {Artifact correction, EEG, Eye Movements, eye tracking, independent component analysis (ICA), regression},
	file = {Full Text PDF:/home/mnk/Zotero/storage/UBUAUN9B/Plöchl et al. - 2012 - Combining EEG and eye tracking identification, characterization, and correction of eye movement art.pdf:application/pdf},
}

@article{lins_ocular_1993,
	title = {Ocular artifacts in recording {EEGs} and event-related potentials {II}: {Source} dipoles and source components},
	volume = {6},
	copyright = {http://www.springer.com/tdm},
	issn = {0896-0267, 1573-6792},
	shorttitle = {Ocular artifacts in recording {EEGs} and event-related potentials {II}},
	url = {http://link.springer.com/10.1007/BF01234128},
	doi = {10.1007/BF01234128},
	language = {en},
	number = {1},
	urldate = {2024-09-18},
	journal = {Brain Topography},
	author = {Lins, Otavio G. and Picton, Terence W. and Berg, Patrick and Scherg, Michael},
	month = sep,
	year = {1993},
	pages = {65--78},
	file = {Full Text PDF:/home/mnk/Zotero/storage/WKPUNHUP/Lins et al. - 1993 - Ocular artifacts in recording EEGs and event-related potentials II Source dipoles and source compon.pdf:application/pdf},
}

@article{berg_dipole_1991,
	title = {Dipole models of eye movements and blinks},
	volume = {79},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00134694},
	url = {https://linkinghub.elsevier.com/retrieve/pii/001346949190154V},
	doi = {10.1016/0013-4694(91)90154-V},
	language = {en},
	number = {1},
	urldate = {2024-09-04},
	journal = {Electroencephalography and Clinical Neurophysiology},
	author = {Berg, Patrick and Scherg, Michael},
	month = jul,
	year = {1991},
	pages = {36--44},
	file = {Berg und Scherg - 1991 - Dipole models of eye movements and blinks.pdf:/home/mnk/Zotero/storage/DA8JBS2V/Berg und Scherg - 1991 - Dipole models of eye movements and blinks.pdf:application/pdf},
}

@article { Barry-1965-aeme-36.9,
    title = "Influence of Eye Lid Movement Upon Electro-Oculographic Recording of Vertical Eye Movements",
    author = "W. Barry and G. Melvill Jones",
    journal = "Aerospace Medicine",
    year = "1965",
    month = sep,
    publisher = "Aerospace Medical Association",
    issn = "0001-9402",
    volume = "36",
    number = "9",
    pages = "855--858",
    url = "https://asma.kglmeridian.com/view/journals/aeme/36/9/article-p855.xml"
}

